# Lab 3: Hiring Signals Pipeline

> Detect hiring signals from Toronto tech job boards and generate qualified sales leads

**The Problem:** Sales teams waste time cold-calling companies that aren't hiring. Hiring is a strong buying signal for B2B products (recruiting tools, HR software, etc.).

**This Solution:** An automated pipeline that:
1. Scrapes Toronto tech job boards weekly
2. Identifies companies with hiring velocity (5+ jobs in 2 weeks = hot lead)
3. Scores leads based on tech stack match and hiring speed
4. Enriches top 10 leads with company data and decision-maker contacts
5. Exports to CRM-ready CSV

**Tech Stack:**
- **Dagster** - Asset-based orchestration (not task-based like Airflow)
- **DuckDB** - Embedded analytics database (4x faster than SQLite, no server needed)
- **Polars** - High-performance dataframes (8x faster than Pandas)

---

## ğŸš€ Quick Start (5 minutes)
```bash
# Clone and setup
git clone https://github.com/NarenSham/buildcpg-lab3-hiring-signals.git
cd buildcpg-lab3-hiring-signals

# Create virtual environment (use Python 3.11 or 3.12)
python3.11 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Initialize database
make db-init

# Start Dagster UI
make dagster-dev
```

Open http://localhost:3000 â†’ Click "Assets" â†’ Click "Materialize All"

---

## ğŸ“Š What You'll See

After materializing assets:
```
Pipeline: raw_jobs â†’ cleaned_jobs â†’ company_stats â†’ lead_scores
                                                         â†“
                                                   enriched_leads
```

**Metrics:**
- 100 raw jobs scraped
- 85 unique jobs after deduplication
- 20 companies analyzed
- Top 5 leads scored and enriched

---

## ğŸ—ï¸ Architecture Decisions

**Why DuckDB over PostgreSQL?**
- No server setup needed (embedded)
- Columnar storage (4-8x faster for analytics)
- Perfect for 10K-1M row datasets
- [Full ADR](docs/adr/001-duckdb-over-postgres.md)

**Why Dagster over Airflow?**
- Asset-based (think "data", not "tasks")
- Better local development experience
- Built-in data quality checks
- [Full ADR](docs/adr/002-dagster-over-airflow.md)

**Why Polars over Pandas?**
- Written in Rust (8x faster)
- Lazy evaluation (optimized query plans)
- Better memory efficiency
- [Benchmark results](scripts/benchmark_polars.py)

---

## ğŸ“ Project Structure
```
lab3_hiring_signals/
â”œâ”€â”€ dagster_lab3/         # Dagster orchestration
â”‚   â”œâ”€â”€ assets/           # Data assets (bronze â†’ silver â†’ gold)
â”‚   â”œâ”€â”€ resources/        # Shared connections (DuckDB)
â”‚   â””â”€â”€ definitions.py    # Dagster entry point
â”œâ”€â”€ src/                  # Core Python logic
â”‚   â”œâ”€â”€ scraper.py        # Job scraper
â”‚   â””â”€â”€ loader.py         # DuckDB loader
â”œâ”€â”€ warehouse/
â”‚   â”œâ”€â”€ schema.sql        # Database DDL
â”‚   â””â”€â”€ *.duckdb          # DuckDB files (gitignored)
â”œâ”€â”€ config/               # Configuration
â”œâ”€â”€ tests/                # Tests
â””â”€â”€ Makefile              # Commands
```

---

## ğŸ¯ Current Status

**Week 1 Complete âœ…**
- [x] Sample data generator (100 Toronto tech jobs)
- [x] DuckDB warehouse setup
- [x] Dagster pipeline (raw_jobs â†’ cleaned_jobs)
- [x] Data quality checks

**Next Up (Week 2):**
- [ ] company_stats asset (aggregate by company)
- [ ] Tech stack extraction
- [ ] lead_scores asset
- [ ] Score explainability

---

## ğŸ’¡ Key Learnings

This project demonstrates:

1. **Asset-based orchestration** - Dagster's dependency management
2. **Columnar analytics** - Why DuckDB beats row-based databases for analytics
3. **Performance optimization** - Polars vs Pandas benchmarks
4. **Data quality engineering** - Asset checks, idempotency
5. **Pragmatic decisions** - Sample data during development, real APIs in production

---

## ğŸ› Troubleshooting

**Error: "No module named 'pyarrow'"**
```bash
pip install pyarrow
```

**Dagster won't start**
```bash
# Check Python version
python --version  # Should be 3.11.x or 3.12.x

# Reinstall dependencies
pip install -r requirements.txt
```

**Database not found**
```bash
make db-init
```

---

## ğŸ¤ Author

**Naren Sham**
- GitHub: [@NarenSham](https://github.com/NarenSham)
- Portfolio: [BuildCPG Labs](https://github.com/NarenSham/buildcpg-labs)

Part of a series demonstrating Staff/Distinguished-level data engineering skills.

---

**â­ Star this repo if you find it helpful!**